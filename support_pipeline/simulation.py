import click
import ete3 as ete
import json
from collections import Counter
from historydag.parsimony import parsimony_score, sankoff_upward, sankoff_upward, load_fasta
from scipy.stats import entropy
import matplotlib.pyplot as plt

@click.group(context_settings={"help_option_names": ["-h", "--help"]})
def cli():
    """
    Command line scripts to facilitate node support validation
    """
    pass


@click.command("parse_clade_stats")
@click.option('--in_file', '-i', help='path to clade_stats.tsv generated by matUtils.')
def parse_clade_stats(in_file):
    """
    Given tsv file of clade stats, find good clades. Use this command to generate stats file:
        
        matUtils summary -i public-2022-10-01.all.masked.pb.gz -c clade_stats.tsv

    """
    
    with open(in_file, "r") as f:
        for line in f.readlines()[1:]:
            row = line.strip().split("\t")
            name = row[0]
            leaf_count = int(row[1])

            if leaf_count <= 100 and leaf_count > 50:
                print(name, "\t", leaf_count)


@click.command("get_tree_stats")
@click.option('--sim_dir', '-s', help='the folder containing TOI and fasta file.')
def get_tree_stats(sim_dir):
    """
    Computes the parsimony score of the simulated tree, the maximum possible parsimony given the
    topology, and the maximum parsimony on the leaves. Stores results as a json at sim_dir/tree_stats.json

    Also computes statistics for the subsetted USHER tree. This can be useful for ensuring that
    the simulations roughly match the real data. This script assumes the directory `sim_dir/..`
    contains the USHER-subsetted newick tree tree.n.nwk.
    """

    var_sites_prefix = sim_dir + "/collapsed_simulated_tree.nwk.variant_sites"
    with open(var_sites_prefix + ".txt", "r") as f:
        idxs = f.readline().split()

    with open(sim_dir + "/ctree_with_refseq.fasta", "r") as f:
        name = f.readline().strip()[1:] # NOTE: Should be `ancestral`
        seq = f.readline()              # Entire sequence
        variants = ""                   # The character values of the nucs that vary
        for i in idxs:
            variants += seq[int(i)-1]

    with open(var_sites_prefix + ".fasta", "r") as f:
        var_sites = f.readlines()

    with open(var_sites_prefix + "_with_refseq.fasta", "w") as f:
        f.write(f">{name}\n")
        f.write(f"{variants}\n")
        for line in var_sites:
            f.write(f"{line}")

    # TODO: Removed for large clades. Check if clade is too large. If so, then don't do this...
    # subprocess.run([
    #     "dnapars_parsimony_score.sh",
    #     var_sites_prefix + "_with_refseq.fasta",    # infasta
    #     name,                                       # root_name
    #     sim_dir                                     # out_dir
    # ])

    # with open(sim_dir + "/dnapars_output.txt", "r") as f:
    #     line = f.readline()
    #     temp = line.strip().split(" ")
    #     best_possible = float(temp[-1])
    best_possible = -1

    tree_path = sim_dir + "/collapsed_simulated_tree.nwk"
    tree = ete.Tree(tree_path) # Doesn't have internal names

    multifurc_counts = Counter()
    for node in tree.traverse():
        if not node.is_leaf():
            multifurc_counts[len(node.children)] += 1

    fasta_path = sim_dir + "/ctree_with_refseq.fasta"   # ancestral seq in second line of this file
    with open(fasta_path, "r") as f:
        assert ">ancestral\n" == f.readline()
        ancestral_seq = f.readline().strip()
    
    # build sequences from mutations
    num_nodes = 0
    num_leaves = 0
    for node in tree.traverse("preorder"):
        num_nodes += 1
        if node.is_leaf():
            num_leaves += 1
        if node.is_root():
            seq = ancestral_seq
        else:
            seq = node.up.sequence
            if len(node.mutations) >= 1:
                for mut in node.mutations.split("|"):
                    mut = mut.strip()
                    curr = mut[0]
                    i = int(mut[1:-1])-1    # convert indices to 0-based
                    new = mut[-1]
                    assert seq[i] == curr
                    seq = seq[:i] + new + seq[i + 1:]
        
        node.add_feature("sequence", seq)

    # just counts mutations between simulated internal node sequences
    tree_score = parsimony_score(tree)

    # computes the best possible parsimony score of any labeling on tree's
    # topology, with root sequence constrained.
    # first replace all internal, non-root sequences with N's, then do
    # sankoff_upward with use_internal_node_sequences True.
    sankoff_tree = tree.copy()
    for node in sankoff_tree.traverse():
        if node.is_root() or node.is_leaf():
            continue
        else:
            node.sequence = "N" * len(tree.sequence)
    max_score = sankoff_upward(sankoff_tree, len(sankoff_tree.sequence), use_internal_node_sequences=True)

    stats_dict = {
        "num_leaves": num_leaves,
        "num_nodes": num_nodes,
        "pars_score": tree_score,
        "max_score_top": max_score,
        "max_score_data": best_possible,
        "multifurc_distribution": multifurc_counts
    }

    # Add similar stats from the USHER tree
    clade_dir = sim_dir.split("/")[0] # TODO: Change this back pls
    usher_tree_path = clade_dir + "/tree.n.nwk"
    print("usher tree path:", usher_tree_path)
    usher_tree = ete.Tree(usher_tree_path, format=1)
    # Remove multifurcations
    to_delete = []
    for node in usher_tree.traverse():
        # TODO: Add leaf check elsewhere as needed
        if not node.is_root() and node.dist==0:
            to_delete.append(node)
    for node in to_delete:
        node.delete(prevent_nondicotomic=False)
    # Remove unifurcations
    to_delete = [node for node in usher_tree.traverse() if len(node.children) == 1 and not node.is_root()]
    for node in to_delete:
        node.delete(prevent_nondicotomic=False)

    pars = 0
    multifurc_counts = Counter()
    node_count = 0
    leaf_count = 0
    for node in usher_tree.traverse():
        node_count += 1
        if node.is_leaf():
            leaf_count += 1
        if not node.is_root():
            pars += node.dist
        if not node.is_leaf():
            multifurc_counts[len(node.children)] += 1
    
    stats_dict["usher_num_leaves"] = leaf_count
    stats_dict["usher_num_nodes"] = node_count
    stats_dict["usher_pars_score"] = pars
    stats_dict["usher_multifurc_distribution"] = multifurc_counts



    outfile = sim_dir + "/tree_stats.json"
    with open(outfile, "w") as f:
        f.write(json.dumps(stats_dict, indent=4))


@click.command("sitewise_entropy")
@click.option('--trial', '-t', help='the trial to compare entropy on.')
def sitewise_entropy(trial):
    """
    Computes the sitewise entropy for a fasta file in the given simulation directory
    """
    base_dir = "/fh/fast/matsen_e/whowards/hdag-benchmark"
    hist_data = {}

    for data_dir in ['data', 'data_new_sim']:
        fasta_path = base_dir + f"/{data_dir}/AY.108/{trial}/simulation/collapsed_simulated_tree.nwk.variant_sites_with_refseq.fasta"
        fasta = load_fasta(fasta_path)
        fasta_keys = list(fasta.keys())

        site_distr = {}
        site_entr = {}
        for site_idx in range(len(fasta['ancestral'])):
            site_distr[site_idx] = Counter()
            for k in fasta_keys:
                site_distr[site_idx][fasta[k][site_idx]] += 1
            site_entr[site_idx] = entropy(list(site_distr[site_idx].values()))

            print(list(site_distr[site_idx].values()), site_entr[site_idx])

        hist_data[data_dir] = [v for v in site_entr.values() if v > 0]
        

    fasta_path = base_dir + f"/{data_dir}/AY.108/real/real_seqs.fasta"
    fasta = load_fasta(fasta_path)
    fasta_keys = list(fasta.keys())

    site_distr = {}
    site_entr = {}
    for site_idx in range(len(list(fasta.values())[0])):
        site_distr[site_idx] = Counter()
        for k in fasta_keys:
            site_distr[site_idx][fasta[k][site_idx]] += 1
        site_entr[site_idx] = entropy(list(site_distr[site_idx].values()))

        if site_entr[site_idx] > 0:
            print(list(site_distr[site_idx].values()), site_entr[site_idx])

    hist_data["real"] = [v for v in site_entr.values() if v > 0]

    max_val = 0
    for k, v in hist_data.items():
        max_val = max(max(v), max_val)

    bins = [el / 20 for el in range(0, int(max_val * 20) + 5)]
    # for k, v in hist_data.items():
    #     plt.hist(v, label=k, bins=bins, alpha=0.3)
    plt.hist([hist_data["real"], hist_data['data'], hist_data['data_new_sim']], bins=bins, label=["Real", "Hypermutation", "MAPLE sim"])

    plt.legend()
    plt.yscale('log')
    plt.savefig(base_dir + f"/data/AY.108/{trial}/simulation/entropy_histogram.png")

    


cli.add_command(parse_clade_stats)
cli.add_command(get_tree_stats)
cli.add_command(sitewise_entropy)

if __name__ == '__main__':
    cli()
